# RunPod Quickstart for Mechanism Testing

**Goal**: Test whether audit-guided per-layer rank patterns provide real benefit beyond compression through controlled shuffled experiments.

## ğŸš€ One-Line Setup

```bash
# SSH into RunPod, then run:
curl -sSL https://raw.githubusercontent.com/your-username/gradience/main/experiments/runpod_launcher.sh | bash
```

## ğŸ“‹ Manual Setup (if needed)

### 1. Create RunPod Instance
- **GPU**: RTX 4090 (24GB) or A100 (40GB+) 
- **Template**: PyTorch 2.1+ or Ubuntu with CUDA
- **Storage**: 100GB+

### 2. Connect and Setup
```bash
# SSH to your instance
ssh root@<runpod-ip> -p <port>

# Clone repository
git clone https://github.com/your-username/gradience.git
cd gradience

# Run automated setup
./experiments/runpod_launcher.sh
```

### 3. HuggingFace Login
When prompted:
1. Get token from: https://huggingface.co/settings/tokens
2. Ensure access to: `mistralai/Mistral-7B-v0.1`
3. Enter token in CLI

### 4. Launch Experiment
Choose option when setup completes:
- **Quick Test**: 30 min validation run
- **Full Experiment**: 6-8 hour 3-seed run  
- **Background**: Run in tmux/nohup

## ğŸ“Š Expected Results

After 6-8 hours, you'll get statistical analysis showing:

### Success Case (Real Mechanism):
```
ğŸ¯ OVERALL CONCLUSION
âœ… HYPOTHESIS CONFIRMED: Audit-guided ranks provide real benefit beyond heterogeneity

ğŸ“Š PERFORMANCE SUMMARY
probe               : 0.650 Â± 0.010
per_layer           : 0.675 Â± 0.008  
per_layer_shuffled  : 0.660 Â± 0.012

ğŸ§¬ MECHANISM BENEFIT TEST
per_layer vs per_layer_shuffled: +0.015 Â± 0.008
âœ“ PASS: Audit-guided placement provides real benefit
```

### Null Case (Heterogeneity Only):
```
ğŸ¯ OVERALL CONCLUSION  
âš ï¸ PARTIAL SUCCESS: Compression works, but no clear mechanism benefit

ğŸ“Š PERFORMANCE SUMMARY
probe               : 0.650 Â± 0.010
per_layer           : 0.672 Â± 0.008
per_layer_shuffled  : 0.670 Â± 0.012

ğŸ§¬ MECHANISM BENEFIT TEST
per_layer vs per_layer_shuffled: +0.002 Â± 0.010
âŒ FAIL: No significant mechanism benefit detected
```

## ğŸ”§ Troubleshooting

**CUDA OOM**: Reduce `per_device_train_batch_size` in config
**Download fails**: Check HF token and model access
**Disk space**: Monitor `/workspace` usage during setup

## ğŸ’° Cost Estimate

**RTX 4090**: ~$6-7 total (setup + 8hr experiment)  
**A100**: ~$18-20 total (faster but pricier)

## ğŸ“ Results Location

```
/workspace/mechanism_test_results/
â”œâ”€â”€ seed_42/bench.json          # Individual results
â”œâ”€â”€ seed_43/bench.json
â”œâ”€â”€ seed_44/bench.json  
â”œâ”€â”€ aggregated_results.json     # Combined statistics
â””â”€â”€ mechanism_analysis.json     # Hypothesis testing
```

Download with: `scp root@<runpod-ip>:/workspace/mechanism_test_results.tar.gz ./`

---

**Scientific Impact**: This experiment tests a fundamental question in LoRA compression - whether audit-guided rank placement behaves like adaptive regularization or if any heterogeneity is sufficient. The shuffled control isolates the mechanism cleanly.