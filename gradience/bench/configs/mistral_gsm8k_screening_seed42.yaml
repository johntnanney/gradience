model:
  name: mistralai/Mistral-7B-v0.1
  type: causal_lm
  torch_dtype: bf16
  gradient_checkpointing: true
  use_cache: false
task:
  dataset: gsm8k
  subset: main
  profile: gsm8k_causal_lm
  eval_max_samples: 200
  generation:
    max_new_tokens: 128
    do_sample: false
    temperature: 0.0
    num_beams: 1
  probe_gate:
    metric: exact_match
    min_value: 0.1
lora:
  probe_r: 32
  alpha: 64
  dropout: 0.05
  target_modules:
  - q_proj
  - k_proj
  - v_proj
  - o_proj
  - gate_proj
  - up_proj
  - down_proj
compression:
  allowed_ranks:
  - 8
  - 16
  - 24
  - 32
  acc_tolerance: 0.025
runtime:
  device: cuda
run_type: mistral_gsm8k_screening_v0.1_seed42
seed: 42
train:
  max_steps: 300
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 16
  learning_rate: 0.0001
  warmup_ratio: 0.03
  weight_decay: 0.0
  logging_steps: 10
  eval_steps: 150
  save_strategy: 'no'
  report_to: none
  seed: 42
  train_samples: 500
