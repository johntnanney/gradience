# Bench v0.1 Certifiable Standard: seed 42
# Canonical benchmark for blog posts and public validation claims
# Spec: DistilBERT+SST-2, r=32 probe, per_layer+safe_uniform_r20+uniform_r24, 3 seeds, 500 steps

model:
  name: distilbert-base-uncased

task:
  dataset: glue
  subset: sst2
  metric: accuracy
  
train:
  max_steps: 500  # Certifiable standard training budget
  eval_steps: 100   
  save_steps: 100   
  
  lr: 0.00005  
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 32
  weight_decay: 0.01
  seed: 42  # Seed 1 of 3 (canonical)
  
  train_samples: 2000  # Full training quality for certifiable status
  eval_samples: 500   

lora:
  probe_r: 32  # Certifiable standard probe rank
  alpha: 32
  dropout: 0.0
  target_modules: ["q_lin","k_lin","v_lin","out_lin"]

compression:
  # Certifiable variants: per_layer (adaptive) + safe_uniform_r20 + conservative_r24
  allowed_ranks: [2, 4, 8, 16, 20, 24, 32]
  acc_tolerance: 0.025

runtime:
  device: cpu

bench_version: "0.1"
run_type: "certifiable_v0.1_seed42"