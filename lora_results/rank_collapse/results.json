{
  "config": {
    "model_name": "distilbert-base-uncased",
    "task": "sst2",
    "lora_rank": 64,
    "lora_alpha": 64,
    "lora_dropout": 0.1,
    "learning_rate": 0.0003,
    "batch_size": 32,
    "num_epochs": 1,
    "max_train_samples": 1000,
    "max_eval_samples": 500,
    "snapshot_interval": 25,
    "seed": 42
  },
  "final_accuracy": 0.53,
  "final_avg_effective_rank": 39.39458673150938,
  "final_avg_utilization": 0.615540417679834,
  "suggested_rank": 64,
  "snapshots": [
    {
      "step": 0,
      "layer_name": "base_model.model.distilbert.transformer.layer.0.attention.q_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.3127988051237,
      "effective_rank_B": 0.0,
      "effective_rank_BA": 0.0,
      "rank_utilization": 0.0,
      "kappa_A": 1.7265758514404297,
      "kappa_B": 1.0,
      "frobenius_BA": 0.0
    },
    {
      "step": 0,
      "layer_name": "base_model.model.distilbert.transformer.layer.0.attention.v_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.32179603307816,
      "effective_rank_B": 0.0,
      "effective_rank_BA": 0.0,
      "rank_utilization": 0.0,
      "kappa_A": 1.7546361684799194,
      "kappa_B": 1.0,
      "frobenius_BA": 0.0
    },
    {
      "step": 0,
      "layer_name": "base_model.model.distilbert.transformer.layer.1.attention.q_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.3255100267803,
      "effective_rank_B": 0.0,
      "effective_rank_BA": 0.0,
      "rank_utilization": 0.0,
      "kappa_A": 1.7647446393966675,
      "kappa_B": 1.0,
      "frobenius_BA": 0.0
    },
    {
      "step": 0,
      "layer_name": "base_model.model.distilbert.transformer.layer.1.attention.v_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.32149409194531,
      "effective_rank_B": 0.0,
      "effective_rank_BA": 0.0,
      "rank_utilization": 0.0,
      "kappa_A": 1.7240862846374512,
      "kappa_B": 1.0,
      "frobenius_BA": 0.0
    },
    {
      "step": 0,
      "layer_name": "base_model.model.distilbert.transformer.layer.2.attention.q_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.313281845287314,
      "effective_rank_B": 0.0,
      "effective_rank_BA": 0.0,
      "rank_utilization": 0.0,
      "kappa_A": 1.7207623720169067,
      "kappa_B": 1.0,
      "frobenius_BA": 0.0
    },
    {
      "step": 0,
      "layer_name": "base_model.model.distilbert.transformer.layer.2.attention.v_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.369762557542984,
      "effective_rank_B": 0.0,
      "effective_rank_BA": 0.0,
      "rank_utilization": 0.0,
      "kappa_A": 1.7033230066299438,
      "kappa_B": 1.0,
      "frobenius_BA": 0.0
    },
    {
      "step": 0,
      "layer_name": "base_model.model.distilbert.transformer.layer.3.attention.q_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.330915333626386,
      "effective_rank_B": 0.0,
      "effective_rank_BA": 0.0,
      "rank_utilization": 0.0,
      "kappa_A": 1.77211594581604,
      "kappa_B": 1.0,
      "frobenius_BA": 0.0
    },
    {
      "step": 0,
      "layer_name": "base_model.model.distilbert.transformer.layer.3.attention.v_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.30338025849594,
      "effective_rank_B": 0.0,
      "effective_rank_BA": 0.0,
      "rank_utilization": 0.0,
      "kappa_A": 1.794919729232788,
      "kappa_B": 1.0,
      "frobenius_BA": 0.0
    },
    {
      "step": 0,
      "layer_name": "base_model.model.distilbert.transformer.layer.4.attention.q_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.346137223642366,
      "effective_rank_B": 0.0,
      "effective_rank_BA": 0.0,
      "rank_utilization": 0.0,
      "kappa_A": 1.7253901958465576,
      "kappa_B": 1.0,
      "frobenius_BA": 0.0
    },
    {
      "step": 0,
      "layer_name": "base_model.model.distilbert.transformer.layer.4.attention.v_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.34501961919522,
      "effective_rank_B": 0.0,
      "effective_rank_BA": 0.0,
      "rank_utilization": 0.0,
      "kappa_A": 1.7633427381515503,
      "kappa_B": 1.0,
      "frobenius_BA": 0.0
    },
    {
      "step": 0,
      "layer_name": "base_model.model.distilbert.transformer.layer.5.attention.q_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.315304616000205,
      "effective_rank_B": 0.0,
      "effective_rank_BA": 0.0,
      "rank_utilization": 0.0,
      "kappa_A": 1.7589112520217896,
      "kappa_B": 1.0,
      "frobenius_BA": 0.0
    },
    {
      "step": 0,
      "layer_name": "base_model.model.distilbert.transformer.layer.5.attention.v_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.273473589873554,
      "effective_rank_B": 0.0,
      "effective_rank_BA": 0.0,
      "rank_utilization": 0.0,
      "kappa_A": 1.802059531211853,
      "kappa_B": 1.0,
      "frobenius_BA": 0.0
    },
    {
      "step": 25,
      "layer_name": "base_model.model.distilbert.transformer.layer.0.attention.q_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.31276861523584,
      "effective_rank_B": 57.40420122244545,
      "effective_rank_BA": 55.68830414362107,
      "rank_utilization": 0.8701297522440792,
      "kappa_A": 1.7263274192810059,
      "kappa_B": 6.751962184906006,
      "frobenius_BA": 0.025721020996570587
    },
    {
      "step": 25,
      "layer_name": "base_model.model.distilbert.transformer.layer.0.attention.v_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.32061847080191,
      "effective_rank_B": 49.34625542416368,
      "effective_rank_BA": 47.07722018116651,
      "rank_utilization": 0.7355815653307267,
      "kappa_A": 1.7548747062683105,
      "kappa_B": 20.13361167907715,
      "frobenius_BA": 0.02835470251739025
    },
    {
      "step": 25,
      "layer_name": "base_model.model.distilbert.transformer.layer.1.attention.q_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.32511748056582,
      "effective_rank_B": 54.31353112626345,
      "effective_rank_BA": 52.661736120397066,
      "rank_utilization": 0.8228396268812042,
      "kappa_A": 1.7644137144088745,
      "kappa_B": 12.706337928771973,
      "frobenius_BA": 0.02571074292063713
    },
    {
      "step": 25,
      "layer_name": "base_model.model.distilbert.transformer.layer.1.attention.v_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.31980324820804,
      "effective_rank_B": 42.21668383862773,
      "effective_rank_BA": 40.44204134088456,
      "rank_utilization": 0.6319068959513212,
      "kappa_A": 1.727194905281067,
      "kappa_B": 40.17805099487305,
      "frobenius_BA": 0.03121209889650345
    },
    {
      "step": 25,
      "layer_name": "base_model.model.distilbert.transformer.layer.2.attention.q_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.31304032474484,
      "effective_rank_B": 51.6431536277882,
      "effective_rank_BA": 49.97518988568119,
      "rank_utilization": 0.7808623419637686,
      "kappa_A": 1.720359206199646,
      "kappa_B": 16.276010513305664,
      "frobenius_BA": 0.026074687018990517
    },
    {
      "step": 25,
      "layer_name": "base_model.model.distilbert.transformer.layer.2.attention.v_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.36831215538187,
      "effective_rank_B": 31.977531999822034,
      "effective_rank_BA": 30.91898809866623,
      "rank_utilization": 0.48310918904165984,
      "kappa_A": 1.7028014659881592,
      "kappa_B": 84.26509857177734,
      "frobenius_BA": 0.031375281512737274
    },
    {
      "step": 25,
      "layer_name": "base_model.model.distilbert.transformer.layer.3.attention.q_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.331187121012825,
      "effective_rank_B": 48.71974152936209,
      "effective_rank_BA": 47.16921274390356,
      "rank_utilization": 0.7370189491234931,
      "kappa_A": 1.7724034786224365,
      "kappa_B": 26.2807559967041,
      "frobenius_BA": 0.026321496814489365
    },
    {
      "step": 25,
      "layer_name": "base_model.model.distilbert.transformer.layer.3.attention.v_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.302052114655105,
      "effective_rank_B": 25.181731799146778,
      "effective_rank_BA": 23.76317404956076,
      "rank_utilization": 0.3712995945243869,
      "kappa_A": 1.7957366704940796,
      "kappa_B": 105.95024871826172,
      "frobenius_BA": 0.03524894639849663
    },
    {
      "step": 25,
      "layer_name": "base_model.model.distilbert.transformer.layer.4.attention.q_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.34541228878112,
      "effective_rank_B": 38.10060566909749,
      "effective_rank_BA": 36.977490491167245,
      "rank_utilization": 0.5777732889244882,
      "kappa_A": 1.7289097309112549,
      "kappa_B": 48.878536224365234,
      "frobenius_BA": 0.029899535700678825
    },
    {
      "step": 25,
      "layer_name": "base_model.model.distilbert.transformer.layer.4.attention.v_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.34378121567605,
      "effective_rank_B": 26.15313175562659,
      "effective_rank_BA": 24.597195373109393,
      "rank_utilization": 0.38433117770483427,
      "kappa_A": 1.7641910314559937,
      "kappa_B": 117.97578430175781,
      "frobenius_BA": 0.034357789903879166
    },
    {
      "step": 25,
      "layer_name": "base_model.model.distilbert.transformer.layer.5.attention.q_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.31554614518028,
      "effective_rank_B": 35.932764586761756,
      "effective_rank_BA": 34.469268176504286,
      "rank_utilization": 0.5385823152578795,
      "kappa_A": 1.7577018737792969,
      "kappa_B": 73.2618637084961,
      "frobenius_BA": 0.029309377074241638
    },
    {
      "step": 25,
      "layer_name": "base_model.model.distilbert.transformer.layer.5.attention.v_lin",
      "nominal_rank": 64,
      "effective_rank_A": 63.273232221187236,
      "effective_rank_B": 30.368869513675467,
      "effective_rank_BA": 28.99522017345072,
      "rank_utilization": 0.4530503152101675,
      "kappa_A": 1.802780032157898,
      "kappa_B": 84.99076843261719,
      "frobenius_BA": 0.03216208517551422
    }
  ],
  "training_history": [
    {
      "step": 25,
      "loss": 0.6786653995513916,
      "avg_rank_utilization": 0.615540417679834
    }
  ]
}