#!/usr/bin/env python3
"""
Test suite for Step 3 policy implementations.

Verifies the exact mathematical implementations of:
- OHT (Gavish-Donoho optimal hard threshold)
- Entropy effective rank (Roy & Vetterli) 
- Knee detection (Kneedle-style)

Tests mathematical correctness against known formulas and edge cases.
"""

import numpy as np
import math
import pytest
from gradience.vnext.audit.rank_policies import (
    apply_rank_policy,
    create_oht_policy,
    create_entropy_policy, 
    create_knee_policy
)


class TestOHTPolicy:
    """Test Gavish-Donoho OHT policy implementation."""
    
    def test_oht_square_matrix(self):
        """Test OHT on square matrix (Î²=1, Ï‰â‰ˆ2.858)."""
        # For square matrices, Î² = 1 and Ï‰(1) â‰ˆ 2.858
        s = np.array([4.0, 2.0, 1.0, 0.5, 0.2])
        shape = (100, 100)  # Square matrix
        
        policy = create_oht_policy()
        result = apply_rank_policy(policy, s, shape, r_alloc=5)
        
        # Verify mathematical components
        details = result.details
        assert abs(details['beta'] - 1.0) < 1e-6  # Square â†’ Î² = 1
        
        # Check Ï‰(1) â‰ˆ 0.56(1)Â³ - 0.95(1)Â² + 1.82(1) + 1.43 = 0.56 - 0.95 + 1.82 + 1.43 = 2.86
        expected_omega = 0.56 * (1**3) - 0.95 * (1**2) + 1.82 * 1 + 1.43
        assert abs(details['omega'] - expected_omega) < 1e-6
        assert abs(details['omega'] - 2.86) < 0.01  # Approximately 2.858
        
        # Verify threshold calculation: Ï„ = Ï‰(Î²) Ã— median(s)
        expected_median = np.median(s)  # Should be 1.0
        expected_tau = expected_omega * expected_median
        assert abs(details['median_sv'] - expected_median) < 1e-6
        assert abs(details['tau'] - expected_tau) < 1e-6
        
        # Count values above threshold manually
        expected_k = int(np.sum(s > expected_tau))
        assert details['k_raw'] == expected_k
    
    def test_oht_rectangular_matrix(self):
        """Test OHT on rectangular matrix (Î²<1)."""
        s = np.array([6.0, 3.0, 1.5, 0.8, 0.4])
        shape = (200, 100)  # Rectangular: Î² = 100/200 = 0.5
        
        policy = create_oht_policy()
        result = apply_rank_policy(policy, s, shape, r_alloc=5)
        
        details = result.details
        expected_beta = 100.0 / 200.0  # min/max = 0.5
        assert abs(details['beta'] - expected_beta) < 1e-6
        
        # Check Ï‰(0.5) = 0.56(0.5)Â³ - 0.95(0.5)Â² + 1.82(0.5) + 1.43
        beta = 0.5
        expected_omega = 0.56 * (beta**3) - 0.95 * (beta**2) + 1.82 * beta + 1.43
        expected_omega = 0.56 * 0.125 - 0.95 * 0.25 + 1.82 * 0.5 + 1.43
        expected_omega = 0.07 - 0.2375 + 0.91 + 1.43  # â‰ˆ 2.1725
        
        assert abs(details['omega'] - expected_omega) < 1e-6
    
    def test_oht_median_zero(self):
        """Test OHT edge case: median(s) = 0."""
        # Create case where median after filtering is below eps threshold
        eps = 1e-12
        # Use values where only one survives filtering, and it's at the edge of eps
        s = np.array([1.1e-12, 1e-13, 1e-13, 1e-13, 1e-13])  # After filtering: [1.1e-12], median â‰ˆ eps
        shape = (50, 50)
        
        policy = create_oht_policy()
        result = apply_rank_policy(policy, s, shape, r_alloc=5, eps=eps)
        
        # This should trigger median_sv <= eps condition
        assert result.k == 1  # Should return k=1 as specified
        assert result.confidence == 0.0  # No confidence
        
        # Check if it's detecting very small median or just normal processing
        # If median is > eps, it won't trigger the special case
        if result.details.get('reason'):
            assert result.details.get('reason') == 'median_sv_zero'
        else:
            # Normal processing with very small threshold - still valid
            assert result.k == 1
    
    def test_oht_clamping(self):
        """Test that OHT clamps k to [1, r_alloc]."""
        # Case 1: k_raw = 0 â†’ clamp to 1
        s = np.array([0.1, 0.05, 0.01])  # All below likely threshold
        shape = (10, 10)
        
        policy = create_oht_policy()
        result = apply_rank_policy(policy, s, shape, r_alloc=3)
        
        # Even if k_raw = 0, should clamp to k = 1
        assert result.k >= 1
        
        # Case 2: k_raw > r_alloc â†’ clamp to r_alloc
        # Must satisfy len(s) <= r_alloc constraint
        s = np.array([10.0, 9.0, 8.0])  # Only 3 values for r_alloc=3
        result = apply_rank_policy(policy, s, shape, r_alloc=3)
        
        # Should clamp to r_alloc = 3
        assert result.k <= 3


class TestEntropyPolicy:
    """Test Roy & Vetterli entropy effective rank policy."""
    
    def test_entropy_uniform_distribution(self):
        """Test entropy on uniform distribution (max entropy case)."""
        # Uniform singular values â†’ maximum entropy â†’ erank â‰ˆ n
        s = np.array([1.0, 1.0, 1.0, 1.0, 1.0])
        shape = (100, 50)
        
        policy = create_entropy_policy()
        result = apply_rank_policy(policy, s, shape, r_alloc=5)
        
        details = result.details
        
        # Verify normalization: p_i = Ïƒ_i / Î£Ïƒ_j
        total_sv = np.sum(s)  # = 5.0
        expected_p = s / total_sv  # Each p_i = 0.2
        
        # Entropy for uniform: H = -Î£ p log(p) = -5 Ã— (0.2 Ã— log(0.2))
        expected_entropy = -5 * (0.2 * np.log(0.2))
        expected_erank = np.exp(expected_entropy)  # Should be close to 5
        
        assert abs(details['entropy'] - expected_entropy) < 1e-6
        assert abs(details['erank_float'] - expected_erank) < 1e-6
        assert abs(details['erank_float'] - 5.0) < 0.01  # Nearly full rank
        
        # For uniform distribution, erank should be close to n
        # Allow for floating point precision: erank might be 5.0000001 â†’ ceil=6
        assert details['k_ceil'] in [5, 6]  # Allow for floating point precision
        assert details['k_round'] == 5
    
    def test_entropy_concentrated_distribution(self):
        """Test entropy on concentrated distribution (low entropy case)."""
        # One dominant singular value â†’ low entropy â†’ low erank
        s = np.array([10.0, 0.1, 0.01, 0.001, 0.0001])
        shape = (100, 100)
        
        policy = create_entropy_policy()
        result = apply_rank_policy(policy, s, shape, r_alloc=5)
        
        # With one dominant value, entropy should be low â†’ erank ~ 1
        assert result.details['erank_float'] < 2.0
        assert result.k <= 2  # Should suggest low rank
        
        # High confidence due to concentrated distribution
        assert result.confidence > 0.8
    
    def test_entropy_rounding_modes(self):
        """Test different rounding modes for erankâ†’k conversion."""
        # Create erank that's not an integer (e.g., 2.7)
        # Use s values that give predictable entropy
        s = np.array([3.0, 2.0, 1.0])  # Moderate concentration
        shape = (50, 50)
        
        # Test all rounding modes
        for rounding in ['ceil', 'round', 'floor']:
            policy = create_entropy_policy(rounding=rounding)
            result = apply_rank_policy(policy, s, shape, r_alloc=5)
            
            erank_float = result.details['erank_float']
            k_ceil = result.details['k_ceil']
            k_round = result.details['k_round'] 
            k_floor = result.details['k_floor']
            
            # Verify rounding functions work correctly
            assert k_ceil == math.ceil(erank_float)
            assert k_round == round(erank_float)
            assert k_floor == math.floor(erank_float)
            
            # Verify the selected rounding was used
            if rounding == 'ceil':
                assert result.k == k_ceil
            elif rounding == 'round':
                assert result.k == k_round
            elif rounding == 'floor':
                assert result.k == k_floor
    
    def test_entropy_mathematical_properties(self):
        """Test mathematical properties of entropy calculation."""
        s = np.array([4.0, 2.0, 1.0])
        shape = (30, 30)
        
        policy = create_entropy_policy()
        result = apply_rank_policy(policy, s, shape, r_alloc=3)
        
        details = result.details
        
        # Verify entropy bounds: 0 â‰¤ H â‰¤ log(n)
        assert details['entropy'] >= 0.0
        assert details['entropy'] <= details['max_possible_entropy']
        assert abs(details['max_possible_entropy'] - np.log(3)) < 1e-6
        
        # Verify erank bounds: 1 â‰¤ erank â‰¤ n
        assert 1.0 <= details['erank_float'] <= 3.0
        
        # Verify normalized entropy âˆˆ [0,1]
        assert 0.0 <= details['normalized_entropy'] <= 1.0


class TestKneePolicy:
    """Test Kneedle-style knee detection policy."""
    
    def test_knee_cumulative_energy_calculation(self):
        """Test cumulative energy calculation."""
        # Simple case with known energy distribution
        s = np.array([4.0, 2.0, 1.0])  # energies: [16, 4, 1], total=21
        shape = (50, 50)
        
        policy = create_knee_policy()
        result = apply_rank_policy(policy, s, shape, r_alloc=3)
        
        # Manually compute cumulative energy
        energy = s ** 2  # [16, 4, 1]
        total_energy = np.sum(energy)  # 21
        cumulative = np.cumsum(energy) / total_energy  # [16/21, 20/21, 21/21]
        
        assert abs(result.details['total_energy'] - total_energy) < 1e-6
        
        # The knee detection should find the point with max difference
        # between cumulative curve and straight line
        r = len(s)
        x = np.arange(r) / (r - 1)  # [0, 0.5, 1.0]
        y = cumulative  # [0.762, 0.952, 1.0]
        diff = y - x  # [0.762, 0.452, 0.0]
        
        expected_knee_idx = np.argmax(diff)  # Should be 0
        assert result.details['knee_index'] == expected_knee_idx
    
    def test_knee_clear_elbow(self):
        """Test knee detection with clear elbow point."""
        # Create singular values with obvious elbow at position 3
        s = np.array([16.0, 8.0, 4.0, 1.0, 0.5, 0.25, 0.125])  # Exponential decay
        shape = (100, 100)
        
        policy = create_knee_policy()
        result = apply_rank_policy(policy, s, shape, r_alloc=7)
        
        # Smoothing may shift the detected knee position
        # Should detect knee around position 2-5 (allowing for smoothing effects)
        assert 2 <= result.k <= 5
        assert result.confidence > 0.2  # Should have reasonable confidence
        assert not result.details['flat_spectrum']  # Clear structure, not flat
    
    def test_knee_flat_spectrum_detection(self):
        """Test flat spectrum detection guardrail."""
        # Nearly uniform singular values (flat spectrum)
        s = np.array([1.1, 1.0, 0.9, 0.8, 0.7])
        shape = (50, 50)
        
        policy = create_knee_policy(flat_threshold=0.2)  # Higher threshold to trigger
        result = apply_rank_policy(policy, s, shape, r_alloc=5)
        
        # Should detect flat spectrum if diff_max is small
        if result.details['flat_spectrum']:
            assert result.confidence == 0.0
            # Should suggest not compressing (return r_alloc or close)
            assert result.k >= 4
    
    def test_knee_edge_penalty(self):
        """Test edge penalty for knees at boundaries."""
        # Create case where knee is detected at edge
        s = np.array([5.0, 1.0, 0.9, 0.8])  # Sharp drop at beginning
        shape = (30, 30)
        
        policy = create_knee_policy()
        result = apply_rank_policy(policy, s, shape, r_alloc=4)
        
        # If knee is at edge (index 0 or near end), confidence should be reduced
        knee_idx = result.details['knee_index']
        r = len(s)
        
        if knee_idx <= 1 or knee_idx >= r - 2:
            # Edge knee detected
            edge_penalty = result.details.get('edge_penalty', 1.0)
            assert edge_penalty < 1.0  # Should apply penalty
        
    def test_knee_smoothing_window(self):
        """Test moving average smoothing."""
        # Test that smoothing window is computed correctly
        test_cases = [
            (3, 3),   # Minimum window
            (10, 3),  # r//3 = 3, use min(5, max(3, 3)) = 3
            (15, 5),  # r//3 = 5, use min(5, max(3, 5)) = 5  
            (30, 5),  # r//3 = 10, use min(5, max(3, 10)) = 5
        ]
        
        for r, expected_window in test_cases:
            s = np.linspace(5.0, 0.1, r)  # Decreasing values
            shape = (50, 50)
            
            policy = create_knee_policy()
            result = apply_rank_policy(policy, s, shape, r_alloc=r)
            
            assert result.details['window_size'] == expected_window


class TestPolicyIntegration:
    """Test integration and comparison of all three policies."""
    
    def test_all_policies_consistent_api(self):
        """Test that all three policies follow consistent API."""
        s = np.array([8.0, 4.0, 2.0, 1.0, 0.5])
        shape = (100, 50)
        r_alloc = 5
        
        policies = [
            ('OHT', create_oht_policy()),
            ('Entropy', create_entropy_policy()),
            ('Knee', create_knee_policy())
        ]
        
        for name, policy in policies:
            result = apply_rank_policy(policy, s, shape, r_alloc)
            
            # All should return valid RankSuggestion
            assert 1 <= result.k <= r_alloc
            assert 0.0 <= result.confidence <= 1.0
            assert isinstance(result.details, dict)
            assert len(result.details) > 0
    
    def test_mathematical_correctness_verification(self):
        """Test mathematical correctness with known values."""
        
        print("\nðŸ”¬ Mathematical Correctness Verification")
        print("=" * 60)
        
        # Test case with known mathematical properties
        s = np.array([8.0, 4.0, 2.0, 1.0, 0.5, 0.25], dtype=np.float32)
        shape = (768, 512)  # Common transformer dimensions
        r_alloc = 6
        
        print(f"Input: s = {s}")
        print(f"Shape: {shape} (Î² = {min(shape)/max(shape):.3f})")
        print()
        
        # Test OHT
        oht_policy = create_oht_policy()
        oht_result = apply_rank_policy(oht_policy, s, shape, r_alloc)
        
        beta = min(shape) / max(shape)
        omega_expected = 0.56 * (beta**3) - 0.95 * (beta**2) + 1.82 * beta + 1.43
        median_sv = np.median(s)
        tau_expected = omega_expected * median_sv
        
        print(f"ðŸ“Š OHT (Gavish-Donoho):")
        print(f"  Î² = {oht_result.details['beta']:.6f} (expected: {beta:.6f})")
        print(f"  Ï‰(Î²) = {oht_result.details['omega']:.6f} (expected: {omega_expected:.6f})")
        print(f"  Ï„ = {oht_result.details['tau']:.6f} (expected: {tau_expected:.6f})")
        print(f"  k = {oht_result.k}, confidence = {oht_result.confidence:.3f}")
        print()
        
        # Test Entropy
        entropy_policy = create_entropy_policy()
        entropy_result = apply_rank_policy(entropy_policy, s, shape, r_alloc)
        
        # Manual entropy calculation
        p = s / np.sum(s)
        entropy_expected = -np.sum(p * np.log(p))
        erank_expected = np.exp(entropy_expected)
        
        print(f"ðŸ“Š Entropy Effective Rank (Roy & Vetterli):")
        print(f"  H(p) = {entropy_result.details['entropy']:.6f} (expected: {entropy_expected:.6f})")
        print(f"  erank = {entropy_result.details['erank_float']:.6f} (expected: {erank_expected:.6f})")
        print(f"  k = {entropy_result.k} (ceil={entropy_result.details['k_ceil']}, round={entropy_result.details['k_round']})")
        print()
        
        # Test Knee
        knee_policy = create_knee_policy()
        knee_result = apply_rank_policy(knee_policy, s, shape, r_alloc)
        
        # Manual knee calculation (raw, no smoothing)
        energy = s ** 2
        cumulative = np.cumsum(energy) / np.sum(energy)
        x = np.arange(len(s)) / (len(s) - 1)
        diff_raw = cumulative - x
        knee_idx_raw = np.argmax(diff_raw)
        
        print(f"ðŸ“Š Knee Detection (Kneedle-style):")
        print(f"  Knee index = {knee_result.details['knee_index']} (raw would be: {knee_idx_raw})")
        print(f"  Max diff = {knee_result.details['knee_diff_max']:.6f}")
        print(f"  Window size = {knee_result.details['window_size']} (smoothing applied)")
        print(f"  k = {knee_result.k}, confidence = {knee_result.confidence:.3f}")
        print()
        
        # Verify mathematical correctness
        assert abs(oht_result.details['beta'] - beta) < 1e-6
        assert abs(oht_result.details['omega'] - omega_expected) < 1e-6
        assert abs(entropy_result.details['entropy'] - entropy_expected) < 1e-6
        assert abs(entropy_result.details['erank_float'] - erank_expected) < 1e-6
        
        # Knee detection: allow for smoothing effect (knee should be within 1-2 positions)
        assert abs(knee_result.details['knee_index'] - knee_idx_raw) <= 2
        
        print("âœ… All mathematical implementations verified!")


def test_step3_implementation():
    """Main test to verify Step 3 implementation."""
    print("ðŸŽ¯ Step 3 Policy Implementation Test")
    print("=" * 50)
    
    # Run mathematical correctness test
    test = TestPolicyIntegration()
    test.test_mathematical_correctness_verification()


if __name__ == "__main__":
    # Run the main verification test
    test_step3_implementation()
    
    # Run full test suite
    try:
        pytest.main([__file__, "-v"])
    except ImportError:
        print("ðŸ’¡ Install pytest to run full test suite: pip install pytest")