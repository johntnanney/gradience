GRADIENCE RESEARCH SYNTHESIS: SPECTRAL METRICS, GROKKING, AND GENERALIZATION
==============================================================================

Date: January 7, 2026
Scope: Complete research arc from grokking studies to LoRA optimization


EXECUTIVE SUMMARY
-----------------

Gradience began as an attempt to predict training outcomes from spectral 
properties of weight matrices. Through extensive experimentation on grokking 
(modular arithmetic), supervised learning (CIFAR-10), and fine-tuning (LoRA 
on Mistral-7B), we discovered:

1. Spectral metrics are diagnostic, not predictive — they describe dynamics 
   but don't forecast outcomes

2. The "restraint principle" governs generalization — constraining updates 
   (via weight decay, low LR, or low α/r) helps across all domains

3. Metrics track a common phenomenon — the balance between fitting capacity 
   and regularization pressure


==============================================================================
PART I: THE GROKKING STUDIES
==============================================================================

Background
----------
Grokking is the phenomenon where neural networks suddenly generalize long 
after memorizing training data. We hypothesized that spectral metrics might 
detect pre-grokking signatures.


Experiments
-----------
Task                    Weight Decay    Grokked?           κ at 10k    κ_recovery
Multiplication (mod 97) 0.1             Yes (at 33.5k)     1,607       11.4
Addition (mod 97)       0.01            No                 19,794      10.4
Addition (mod 97)       0.1             No                 ~1,000      1.0


Key Findings
------------

1. κ DIVERGENCE AS EARLY SIGNAL

   Step 10,000:
     Multiplication κ: 1,607   (later grokked)
     Addition κ:      19,794   (never grokked)
   
   κ ratio: 12.3x — divergence visible before grokking


2. κ_RECOVERY METRIC

   κ_recovery = κ_peak / κ_final

   High κ_recovery → κ spiked then recovered → model reorganizing
   Low κ_recovery  → κ stayed high → model stuck


3. THE HONEST FINDING

   Low κ_recovery  → Won't grok    (strong negative signal)
   High κ_recovery → Might grok    (necessary but not sufficient)

   κ_recovery is like heart rate during exercise:
   - Very high → definitely stressed, consider stopping
   - Normal → doesn't guarantee you'll finish the marathon


Interpretation
--------------
Grokking appears to involve:

1. Initial memorization — κ increases as network fits training data
2. Reorganization — κ recovers as network finds generalizing solution
3. Compression — effective rank decreases as simpler structure emerges

Spectral metrics *track* this process but don't *cause* it. The causal 
factor seems to be weight decay — stronger regularization pressure forces 
the network to find compressed, generalizing solutions.


==============================================================================
PART II: THE LORA FINE-TUNING STUDIES
==============================================================================

Background
----------
We applied spectral analysis to LoRA adapters, measuring utilization 
(stable_rank / r) and dominance (adapter contribution vs base model).


The 2x2 Grid (GSM8K Accuracy)
-----------------------------
           α/r=1.0    α/r=0.25
r=32       20%        36%
r=8        24%        35%


Key Findings
------------

1. α/r CONTROLS GENERALIZATION

   Baseline (α/r=1.0):    20% accuracy, gap=1.64x, stable_rank=4.66
   Low α/r (α/r=0.25):    36% accuracy, gap=1.45x, stable_rank=2.25


2. BUT LR DOMINATES α/r

   Baseline (LR=2e-4):   20% accuracy
   Baseline (LR=5e-5):   38% accuracy  ← Just lower LR!


3. AT LOW LR, α/r DOESN'T MATTER

   attn_r8 (α/r=1.0, LR=5e-5):   34.5%
   attn_r8 (α/r=0.25, LR=5e-5):  35.0%

   Difference: 0.5% (noise)


4. STABLE RANK TRACKS UPDATE CONCENTRATION

   High α/r → stable_rank ≈ 4.66 → diffuse updates → memorization
   Low α/r  → stable_rank ≈ 2.25 → concentrated updates → generalization
   Low LR   → stable_rank ≈ 1.30 → ultra-concentrated → best generalization


Interpretation
--------------
LoRA generalization follows the same pattern as grokking:

- Restraint helps — lower LR, lower α/r, fewer modules
- Concentration correlates with generalization — lower stable rank = better
- Metrics describe but don't predict — stable rank tells you *what* is 
  happening, not *what will* happen


==============================================================================
PART III: THE UNIFYING PRINCIPLE
==============================================================================

The Restraint Hypothesis
------------------------
Across all experiments, constraining update dynamics improves generalization:

Domain          Restraint Mechanism     Effect
------          -------------------     ------
Grokking        Weight decay            Forces κ recovery, enables reorganization
LoRA (α/r)      Lower α/r               Reduces adapter amplitude, concentrates updates
LoRA (LR)       Lower learning rate     Reduces step size, prevents overfitting
LoRA (targets)  Attention-only          Prevents MLP overwriting base knowledge


Why Restraint Works
-------------------
Without restraint:
  - Large updates → model can "carve out" arbitrary directions
  - High effective rank → memorization shortcuts available
  - Training loss drops fast, test loss lags → overfitting

With restraint:
  - Small updates → model must be selective
  - Low effective rank → only essential features survive
  - Training/test loss converge → generalization


Spectral Metrics as "Force Balance" Indicators
----------------------------------------------
The condition number κ and stable rank measure the balance between:

- Learning pressure — gradients pushing weights to fit data
- Regularization pressure — weight decay / small LR pulling toward origin

High κ / High stable rank:
  - Learning winning → fitting training data
  - Capacity being consumed → risk of memorization

Low κ / Low stable rank (after training):
  - Regularization winning → compressed solution
  - Capacity released → generalizing


==============================================================================
PART IV: WHAT METRICS CAN AND CANNOT DO
==============================================================================

What Spectral Metrics CAN Do
----------------------------
Capability                  Example                                    Confidence
----------                  -------                                    ----------
Detect struggling runs      κ divergence before grokking failure       High
Diagnose capacity usage     Stable rank shows 14% utilization          High
Track update dynamics       Stable rank drops → updates concentrating  High
Audit efficiency            "Your 83.9M adapter uses 4.66 eff dims"    High


What Spectral Metrics CANNOT Do
-------------------------------
Limitation                      Why                                    Alternative
----------                      ---                                    -----------
Predict final accuracy          Too many confounds                     Use early eval
Recommend optimal config        Optimal depends on task difficulty     Use heuristics
Replace hyperparameter tuning   Metrics describe, don't prescribe      Still need LR sweep
Guarantee success               Necessary but not sufficient signals   Monitor train/test gap


The Honest Positioning
----------------------
Gradience is a "flight recorder + mechanic" for training:

  YES: It detects when you're stalling, overfitting, or wasting capacity
  YES: It recommends known-good adjustments based on regime
  YES: It audits efficiency (are you using your rank budget?)

  NO: It doesn't predict the destination
  NO: It doesn't replace evaluation
  NO: It doesn't guarantee success


==============================================================================
PART V: PRACTICAL RECOMMENDATIONS
==============================================================================

For Grokking / Long Training
----------------------------
# Increase weight decay if κ keeps growing
if kappa_growth_rate > 50x in first 5k steps:
    increase_weight_decay()

# Monitor κ_recovery for reorganization signal
if kappa_recovery < 2.0:
    warn("Model may be stuck - consider early stopping")


For LoRA Fine-Tuning
--------------------
# Universal efficient config
LoraConfig(
    r=8,
    lora_alpha=8,  # α/r=1.0 is fine with low LR
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
)
optimizer = AdamW(lr=5e-5)  # THE KEY LEVER

# Monitor generalization gap
if test_ppl / train_ppl > 1.5:
    warn("Memorization detected")


Decision Tree
-------------
Is task easy (classification, NER)?
  → Any reasonable config works, optimize for efficiency
  
Is task hard (reasoning, math, code)?
  → Use lr=5e-5, attention-only, r=8
  → Monitor train/test gap
  
Is model struggling (high κ, high gap)?
  → Increase restraint (lower LR, higher weight decay)
  
Is model undertrained (low stable rank but poor accuracy)?
  → May need more capacity or different approach


==============================================================================
PART VI: THE ROLE OF SPECTRAL METRICS GOING FORWARD
==============================================================================

Research Value
--------------
Spectral metrics provide a language for understanding training dynamics:

- κ tracks "conditioning" — how anisotropic the loss landscape is
- Stable rank tracks "effective dimensionality" — how concentrated updates are
- Effective rank tracks "information content" — how much capacity is used

This language helps us reason about generalization even if it doesn't predict it.


Product Value
-------------
The practical value isn't in the metrics themselves but in the knowledge 
they helped discover:

1. Lower LR helps generalization (found via gap + accuracy experiments)
2. Attention-only beats all-modules (found via targeted ablation)
3. r=8 is sufficient (found via utilization analysis)

A product could encode this knowledge as default recommendations without 
exposing spectral metrics to users.


The Deeper Question
-------------------
Our research touched on a fundamental question in deep learning:

   Why does restraint help generalization?

Possible answers:
- Implicit regularization — small updates favor flat minima
- Lottery ticket hypothesis — restraint forces finding essential subnetworks  
- Information bottleneck — compression in weights → compression in representations
- Loss landscape geometry — restraint keeps you in "good" basins

Spectral metrics give us a window into these dynamics even if they don't 
give us control over them.


==============================================================================
PART VII: COMPARISON TABLE
==============================================================================

Aspect              Grokking Research           LoRA Research
------              -----------------           -------------
Task                Modular arithmetic          GSM8K math reasoning
Model               Small MLP                   Mistral-7B
Key metric          κ (condition number)        Stable rank
Restraint mechanism Weight decay                Learning rate
Key finding         κ_recovery needed           LR=5e-5 dominates α/r
Predictive power    Necessary not sufficient    Diagnostic only
Practical output    "Detect struggling runs"    "Use lr=5e-5, attention-only"


==============================================================================
CONCLUSION
==============================================================================

What We Set Out To Do
---------------------
Build a tool that predicts training outcomes from spectral properties.


What We Actually Found
----------------------
1. Spectral metrics describe dynamics but don't predict outcomes
2. The restraint principle (small updates → generalization) appears across domains
3. Simple interventions (lower LR, attention-only) outperform sophisticated metrics
4. The train/test gap is the most actionable metric


What This Means for Gradience
-----------------------------
As a research tool: 
  Valuable for understanding training dynamics and testing hypotheses 
  about generalization.

As a product: 
  The value is in the accumulated knowledge (lr=5e-5, attention-only, r=8) 
  more than the metrics themselves.

The honest pitch:
  "We ran the experiments so you don't have to. Here's what works, 
   and here are tools to understand why."


==============================================================================
APPENDIX: ALL EXPERIMENTAL RESULTS
==============================================================================

Grokking Experiments
--------------------
Task    WD      Grokked?    Step    κ_final     κ_recovery
----    --      --------    ----    -------     ----------
Mult    0.1     Yes         33.5k   ~1,600      11.4
Add     0.01    No          —       ~20,000     10.4
Add     0.1     No          —       ~1,000      1.0


LoRA Experiments (GSM8K)
------------------------
Config          r   α/r     LR      Targets Params  Accuracy
------          -   ---     --      ------- ------  --------
baseline        32  1.0     2e-4    all     83.9M   20%
baseline_lr5e5  32  1.0     5e-5    all     83.9M   38%    *BEST*
low_alpha       32  0.25    2e-4    all     83.9M   36%
small_r8        8   1.0     2e-4    all     21.0M   24%
low_alpha_r8    8   0.25    2e-4    all     21.0M   35%
mlp_only        32  1.0     2e-4    mlp     56.6M   16%
attn_only       32  0.25    2e-4    attn    27.3M   38%
attn_r8_lr5e5   8   1.0     5e-5    attn    6.8M    35%    *EFFICIENT*


LoRA Experiments (SST-2)
------------------------
Config              Accuracy
------              --------
baseline_lr5e5      96.0%
attn_r8_lr5e5       95.6%
baseline_lr2e4      95.0%
low_alpha_lr2e4     94.0%


==============================================================================

This document represents the complete research arc of Gradience, from 
initial hypothesis through experimental validation to practical recommendations.

Generated: January 7, 2026
